est_effect = est_effect / OJA
) %>%
ggplot(aes(x = dmax, y = est_effect)) +
geom_line() +
labs(title = "Estimated effect of ChatGPT on OJA",
x = "dmax",
y = "Estimated effect") +
theme_minimal()
did_model_loglin <- feols(
log_OJA ~ ai_product_exposure_score * post_chatgpt |
idesco_level_2 + idcountry + dmax,
data = oja_twfe,
cluster = c("idcountry", "idesco_level_2")
)
did_model_loglin
# back-of-the-envelope ----------------------------------------------------
oja_twfe_est <- oja_twfe %>%
mutate(
est = predict(did_model_twoway),
est_cf = predict(
did_model_twoway, newdata = mutate(oja_twfe, post_chatgpt = 0)
),
est_effect = (est - est_cf) * post_chatgpt, # to handle some e-11 type numbers
est_loglin_pairs = exp(predict(did_model_loglin_pairs)),
est_cf_loglin_pairs = exp(predict(
did_model_loglin_pairs, newdata = mutate(oja_twfe, post_chatgpt = 0)
)),
est_effect_loglin_pairs = (est_loglin_pairs - est_cf_loglin_pairs) * post_chatgpt,
est_loglin = exp(predict(did_model_loglin)),
est_cf_loglin = exp(predict(
did_model_loglin, newdata = mutate(oja_twfe, post_chatgpt = 0)
)),
est_effect_loglin = (est_loglin - est_cf_loglin) * post_chatgpt
)
sum(oja_twfe_est$est_effect_loglin)
oja_twfe_est %>%
group_by(dmax) %>%
summarise(
est_effect = sum(est_effect_loglin),
OJA = sum(OJA)
) %>%
mutate(
est_effect = est_effect / OJA
) %>%
ggplot(aes(x = dmax, y = est_effect)) +
geom_line() +
labs(title = "Estimated effect of ChatGPT on OJA",
x = "dmax",
y = "Estimated effect") +
theme_minimal()
feols(
log_OJA ~ log_ai_product_exposure_score * post_chatgpt |
idesco_level_2 + idcountry + dmax,
data = oja_twfe
)
feols(
log_OJA ~ log_ai_product_exposure_score * post_chatgpt |
country_occupation_pair + dmax,
data = oja_twfe,
cluster = c("country_occupation_pair")
)
feols(
OJA ~ ai_product_exposure_score * post_chatgpt |
idesco_level_2 + idcountry + dmax,
data = oja_twfe,
cluster = c("idcountry")
) %>%
summary()
library(tidyverse)
library(fixest)
# read data ---------------------------------------------------------------
oja <- list.files("data/cedefop_skills_ovate/csv", full.names = TRUE) %>%
map_dfr(read_csv)
ai_exposure <- read_csv(
"data/ai_exposure_scores/scored_esco_occupations_isco_2_digit.csv"
)
oja %>%
group_by(esco_level_2_short, dmax) %>%
summarise(OJA = sum(OJA)) %>%
ungroup() %>%
arrange(desc(esco_level_2_short), (dmax)) %>%
print(n = Inf)
# prep for model ----------------------------------------------------------
oja_twfe <- oja %>%
select(OJA, dmax, idcountry, esco_level_2_short, idesco_level_2) %>%
mutate(
post_chatgpt = ifelse(
dmax >= as.Date("2022-11-30"),
1,
0
)
) %>%
left_join(
ai_exposure %>%
select(idesco_level_2 = isco_level_2, ai_product_exposure_score) %>%
mutate(idesco_level_2 = paste0("OC", idesco_level_2)),
by = "idesco_level_2"
) %>%
mutate(
country_occupation_pair = paste0(idcountry, "_", idesco_level_2)
) %>%
filter(
!is.na(ai_product_exposure_score)
) %>%
mutate(
# add log of OJA
log_OJA = log(OJA + 1), # +1 just in case to handle potenital 0s
# scale ai_product_exposure_score from 0 to 1
ai_product_exposure_score = (ai_product_exposure_score - min(ai_product_exposure_score)) /(max(ai_product_exposure_score) - min(ai_product_exposure_score)),
log_ai_product_exposure_score = log(ai_product_exposure_score + 1)
)
nrow(oja_twfe)
length(unique(oja_twfe$country_occupation_pair))
length(unique(oja_twfe$idesco_level_2))
length(unique(oja_twfe$idcountry))
length(unique(oja_twfe$dmax))
# regress OJA on dmax dummies, idcountry dummies, and a interaction between
# post_chatgpt and ai_product_exposure_score
lm(
OJA ~
I(post_chatgpt * ai_product_exposure_score) +
as.factor(dmax) +
idcountry -
1,
data = oja_twfe
) %>%
summary()
feols(
log_OJA ~ log_ai_product_exposure_score * post_chatgpt |
idesco_level_2 + idcountry + dmax,
data = oja_twfe,
cluster = c("idesco_level_2", "idcountry")
)
# using fixest ------------------------------------------------------------
did_model_twoway <- feols(
OJA ~ ai_product_exposure_score * post_chatgpt |
idesco_level_2 + idcountry + dmax,
data = oja_twfe,
cluster = c("idesco_level_2", "idcountry")
)
# using fixest ------------------------------------------------------------
did_model_twoway <- feols(
OJA ~ ai_product_exposure_score * post_chatgpt |
idesco_level_2 + idcountry + dmax,
data = oja_twfe,
cluster = c("idesco_level_2", "idcountry")
)
feols(
log_OJA ~ log_ai_product_exposure_score * post_chatgpt |
idesco_level_2 + idcountry + dmax,
data = oja_twfe,
cluster = c("idesco_level_2", "idcountry")
)
did_model_loglin_pairs <- feols(
log_OJA ~ ai_product_exposure_score * post_chatgpt |
country_occupation_pair + dmax,
data = oja_twfe,
cluster = c("country_occupation_pair")
)
did_model_loglin_pairs
did_model_loglin <- feols(
log_OJA ~ ai_product_exposure_score * post_chatgpt |
idesco_level_2 + idcountry + dmax,
data = oja_twfe,
cluster = c("idcountry", "idesco_level_2")
)
did_model_loglin
feols(
log_OJA ~ log_ai_product_exposure_score * post_chatgpt |
idesco_level_2 + idcountry + dmax,
data = oja_twfe
)
# back-of-the-envelope ----------------------------------------------------
oja_twfe_est <- oja_twfe %>%
mutate(
est = predict(did_model_twoway),
est_cf = predict(
did_model_twoway, newdata = mutate(oja_twfe, post_chatgpt = 0)
),
est_effect = (est - est_cf) * post_chatgpt, # to handle some e-11 type numbers
est_loglin_pairs = exp(predict(did_model_loglin_pairs)),
est_cf_loglin_pairs = exp(predict(
did_model_loglin_pairs, newdata = mutate(oja_twfe, post_chatgpt = 0)
)),
est_effect_loglin_pairs = (est_loglin_pairs - est_cf_loglin_pairs) * post_chatgpt,
est_loglin = exp(predict(did_model_loglin)),
est_cf_loglin = exp(predict(
did_model_loglin, newdata = mutate(oja_twfe, post_chatgpt = 0)
)),
est_effect_loglin = (est_loglin - est_cf_loglin) * post_chatgpt
)
sum(oja_twfe_est$est_effect)
sum(oja_twfe_est$est)
sum(oja_twfe_est$est_effect) / sum(oja_twfe_est$est)
sum(oja_twfe_est$est_effect) / sum(oja_twfe_est$OJA)
sum(oja_twfe_est$est_effect_loglin_pairs)
sum(oja_twfe_est$est_effect_loglin)
oja_twfe_est %>%
group_by(dmax) %>%
summarise(
est_effect = sum(est_effect),
OJA = sum(OJA)
) %>%
mutate(
est_effect = est_effect / OJA
) %>%
ggplot(aes(x = dmax, y = est_effect)) +
geom_line() +
labs(title = "Estimated effect of ChatGPT on OJA",
x = "dmax",
y = "Estimated effect") +
theme_minimal()
oja_twfe_est %>%
group_by(dmax) %>%
summarise(
est_effect = sum(est_effect_loglin_pairs),
OJA = sum(OJA)
) %>%
mutate(
est_effect = est_effect / OJA
) %>%
ggplot(aes(x = dmax, y = est_effect)) +
geom_line() +
labs(title = "Estimated effect of ChatGPT on OJA",
x = "dmax",
y = "Estimated effect") +
theme_minimal()
oja_twfe %>% select(log_OJA, ai_product_exposure_score, post_chatgpt, idesco_level_2, idcountry, dmax)
# Load necessary libraries
library(brms)
library(tidybayes)
library(tidyverse)
# read data ---------------------------------------------------------------
oja <- list.files("data/cedefop_skills_ovate/csv", full.names = TRUE) %>%
map_dfr(read_csv)
ai_exposure <- read_csv(
"data/ai_exposure_scores/scored_esco_occupations_isco_2_digit.csv"
)
oja %>%
group_by(esco_level_2_short, dmax) %>%
summarise(OJA = sum(OJA)) %>%
ungroup() %>%
arrange(desc(esco_level_2_short), (dmax)) %>%
print(n = Inf)
# prep for model ----------------------------------------------------------
oja_twfe <- oja %>%
select(OJA, dmax, idcountry, esco_level_2_short, idesco_level_2) %>%
mutate(
post_chatgpt = ifelse(
dmax >= as.Date("2022-11-30"),
1,
0
)
) %>%
left_join(
ai_exposure %>%
select(idesco_level_2 = isco_level_2, ai_product_exposure_score) %>%
mutate(idesco_level_2 = paste0("OC", idesco_level_2)),
by = "idesco_level_2"
) %>%
mutate(
country_occupation_pair = paste0(idcountry, "_", idesco_level_2)
) %>%
filter(
!is.na(ai_product_exposure_score)
) %>%
mutate(
# add log of OJA
log_OJA = log(OJA + 1), # +1 just in case to handle potenital 0s
# scale ai_product_exposure_score from 0 to 1
ai_product_exposure_score = (ai_product_exposure_score - min(ai_product_exposure_score)) /(max(ai_product_exposure_score) - min(ai_product_exposure_score)),
log_ai_product_exposure_score = log(ai_product_exposure_score + 1)
)
oja_twfe %>%
mutate(
time_factor = factor(format(dmax, "%Y-%m")),  # Create factor for each month-year combination
ai_exposure_post_chatgpt = ai_product_exposure_score * post_chatgpt
)
# run ---------------------------------------------------------------------
oja_twfe <- oja_twfe %>%
mutate(
time_factor = factor(format(dmax, "%Y-%m")),  # Create factor for each month-year combination
ai_exposure_post_chatgpt = ai_product_exposure_score * post_chatgpt
)
# Set up the formula without intercept and with time dummies
formula <- bf(
log_OJA ~ 0 + ai_exposure_post_chatgpt + time_factor +
(1 | idcountry) + (1 | idesco_level_2)
)
# Set up priors
priors <- c(
# Prior for the ai_exposure_post_chatgpt coefficient
prior(normal(0, 0.5), class = "b", coef = "ai_exposure_post_chatgpt"),
# Priors for time factor levels (one for each month-year combination)
prior(normal(10, 2), class = "b", coef = "time_factor"),
# Priors for the standard deviations of the random effects
prior(exponential(1), class = "sd", group = "idcountry"),
prior(exponential(1), class = "sd", group = "idesco_level_2"),
# Prior for the residual standard deviation
prior(exponential(1), class = "sigma")
)
# Fit the model
bayesian_did_model_no_intercept <- brm(
formula = formula,
data = oja_twfe,
family = gaussian(),
prior = priors,
cores = 4,
chains = 4,
iter = 4000,
warmup = 2000,
control = list(adapt_delta = 0.95)
)
# Set up priors
priors <- c(
# Prior for the ai_exposure_post_chatgpt coefficient
prior(normal(0, 0.5), class = "b", coef = "ai_exposure_post_chatgpt"),
# Priors for time factor levels (one for each month-year combination)
prior(normal(10, 2), class = "b", coef = "time_factor.+"),
# Priors for the standard deviations of the random effects
prior(exponential(1), class = "sd", group = "idcountry"),
prior(exponential(1), class = "sd", group = "idesco_level_2"),
# Prior for the residual standard deviation
prior(exponential(1), class = "sigma")
)
# Fit the model
bayesian_did_model_no_intercept <- brm(
formula = formula,
data = oja_twfe,
family = gaussian(),
prior = priors,
cores = 4,
chains = 4,
iter = 4000,
warmup = 2000,
control = list(adapt_delta = 0.95)
)
# Set up priors
priors <- c(
# Prior for the ai_exposure_post_chatgpt coefficient
prior(normal(0, 0.5), class = "b", coef = "ai_exposure_post_chatgpt"),
# Priors for time factor levels (one for each month-year combination)
#prior(normal(10, 2), class = "b", coef = "time_factor.+"),
# Priors for the standard deviations of the random effects
prior(exponential(1), class = "sd", group = "idcountry"),
prior(exponential(1), class = "sd", group = "idesco_level_2"),
# Prior for the residual standard deviation
prior(exponential(1), class = "sigma")
)
# Fit the model
bayesian_did_model_no_intercept <- brm(
formula = formula,
data = oja_twfe,
family = gaussian(),
prior = priors,
cores = 4,
chains = 4,
iter = 4000,
warmup = 2000,
control = list(adapt_delta = 0.95)
)
# Summarize the results
summary(bayesian_did_model_no_intercept)
# Plot the posterior distributions
mcmc_plot(bayesian_did_model_no_intercept, type = "areas", regex_pars = "b_")
# Plot the posterior distributions
mcmc_plot(bayesian_did_model_no_intercept, type = "areas", regex_pars = "b_ai_")
# Plot time effects
time_effects <- conditional_effects(bayesian_did_model_no_intercept, effects = "time_factor")
plot(time_effects)
bayesian_did_model_no_intercept$data
bayesian_did_model_no_intercept$prior
bayesian_did_model_no_intercept$fit
bayesian_did_model_no_intercept$fit$b_ai_exposure_post_chatgpt
# Plot the posterior distributions
mcmc_plot(bayesian_did_model_no_intercept, type = "areas", regex_pars = "b_ai_")
nama_10_lp <- read_csv("data/eurostat_nama_10_prod/estat_nama_10_lp_a21.tsv")
library(tidyverse)
nama_10_lp <- read_csv("data/eurostat_nama_10_prod/estat_nama_10_lp_a21.tsv")
nama_10_lp <- read_tsv("data/eurostat_nama_10_prod/estat_nama_10_lp_a21.tsv")
nama_10_lp <- read_delim(
"data/eurostat_nama_10_prod/estat_nama_10_lp_a21.tsv", sep = "\t"
)
nama_10_lp <- read_delim(
"data/eurostat_nama_10_prod/estat_nama_10_lp_a21.tsv", delim = "\t"
)
nama_10_lp
nama_10_lp
tidy_up_data <- function(df) {
first_col_name <- names(df)[1]
num_separators <- str_count(df[[first_col_name]][1], ",")
new_col_names <- str_split(df[[first_col_name]][1], ",")[[1]]
df %>%
pivot_longer(
cols = -1,
names_to = "t",
values_to = "value"
) %>%
separate(
col = first_col_name,
into = new_col_names,
sep = ","
)
}
tidy_up_data(nama_10_lp)
names(nama_10_lp)[1]
names(nama_10_lp)[1] %>% str_remove("\\\\.*")
tidy_up_data <- function(df) {
first_col_name <- names(df)[1] %>%
str_remove("\\\\.*")
num_separators <- str_count(first_col_name, ",")
new_col_names <- str_split(first_col_name, ",")[[1]]
df %>%
pivot_longer(
cols = -1,
names_to = "t",
values_to = "value"
) %>%
separate(
col = first_col_name,
into = new_col_names,
sep = ","
)
}
nama_10_lp_tidy <- tidy_up_data(nama_10_lp)
tidy_up_data <- function(df) {
first_col_name <- names(df)[1]
num_separators <- str_count(first_col_name, ",")
new_col_names <- str_split(first_col_name %>% str_remove("\\\\.*"), ",")[[1]]
df %>%
pivot_longer(
cols = -1,
names_to = "t",
values_to = "value"
) %>%
separate(
col = first_col_name,
into = new_col_names,
sep = ","
)
}
nama_10_lp_tidy <- tidy_up_data(nama_10_lp)
nama_10_lp_tidy
nama_10_lp_tidy$t %>% table
nama_10_lp_tidy$na_item %>% table
nama_10_lp_tidy$unit %>% table
nama_10_lp_tidy$freq %>% table
nama_10_lp_tidy$geo %>% table
nama_10_lp_tidy$value %>% sample(10)
nama_10_lp_tidy$value %>% sample(10)
nama_10_lp_tidy$value %>% sample(10)
nama_10_lp_tidy$value %>% sample(10)
nama_10_lp_tidy$value %>% sample(10)
nama_10_lp_tidy$value %>% sample(10)
nama_10_lp_tidy$value %>% sample(10)
nama_10_lp_tidy$value %>% sample(10)
nama_10_lp_tidy$value %>% sample(10)
nama_10_lp_tidy$value %>% sample(10)
nama_10_lp_tidy$value %>% sample(10)
nama_10_lp_tidy$value %>% sample(10)
nama_10_lp_tidy$value %>% sample(10)
nama_10_lp_tidy$value %>% sample(10)
nama_10_lp_tidy$value %>% sample(10)
nama_10_lp_tidy$value %>% sample(10)
nama_10_lp_tidy$value %>% sample(10)
nama_10_lp_tidy$value %>% sample(10)
nama_10_lp_tidy$value %>% sample(10)
nama_10_lp_tidy$value %>% sample(10)
nama_10_lp_tidy$value %>% sample(10)
nama_10_lp_ulc <- read_delim(
"data/eurostat_nama_10_prod/estat_nama_10_lp_ulc.tsv", delim = "\t"
)
nama_10_cp <- read_delim(
"data/eurostat_nama_10_prod/estat_nama_10_cp_a21.tsv", delim = "\t"
)
nama_10_a10 <- read_delim(
"data/eurostat_nama_10_prod/estat_nama_10_a10.tsv", delim = "\t"
)
nama_10_lp_ulc_tidy <- tidy_up_data(nama_10_lp_ulc)
nama_10_cp_tidy <- tidy_up_data(nama_10_cp)
nama_10_a10_tidy <- tidy_up_data(nama_10_a10)
nama_10_lp_ulc_tidy
nama_10_cp_tidy
nama_10_lp_tidy
nama_10_lp_tidy$nace_r2 %>% table
nama_10_lp_ulc_tidy
nama_10_lp_ulc
nama_10_cp_tidy
nama_10_a10_tidy
nama_10_cp_tidy
nama_10_lp_tidy$unit %>% table
nama_10_lp_tidy$na_item %>% table
nama_10_lp_ulc
nama_10_lp_ulc_tidy
nama_10_lp_ulc_tidy$na_item %>% table
nama_10_cp_tidy
nama_10_cp_tidy$na_item %>% table
nama_10_a10
nama_10_a10_tidy
nama_10_a10_tidy$na_item %>% table
nama_10_lp_tidy
nama_10_lp_tidy$unit %>% table()
nama_10_lp_tidy %>% filter(str_detect(value, "p"))
table(nama_10_lp_tidy$unit, nama_10_lp_tidy$na_item)
table(nama_10_lp_ulc_tidy$unit, nama_10_lp_ulc_tidy$na_item)
table(nama_10_cp_tidy$unit, nama_10_cp_tidy$na_item)
nama_10_lp_ulc_tidy
max(nama_10_lp_tidy$y)
max(nama_10_lp_tidy$t)
max(nama_10_cp_tidy$t)  # [1] "2020-01-01")
nama_10_a10
nama_10_a10_tidy$freq %>% table
